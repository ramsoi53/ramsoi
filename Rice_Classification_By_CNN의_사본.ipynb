{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 3399185,
          "sourceType": "datasetVersion",
          "datasetId": 2049052
        }
      ],
      "dockerImageVersionId": 30528,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ramsoi53/ramsoi/blob/main/Rice_Classification_By_CNN%EC%9D%98_%EC%82%AC%EB%B3%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'rice-image-dataset:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F2049052%2F3399185%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240514%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240514T144027Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3Db168b73f75a9764fcebeb2995434a7c9c3e451456e6ee08b7d7074d51c154161974779b1cc6b6ee2a2bda7f524c3327e6a9cb58681e167709317dcbb12781d60a22f986c71df5f219b1e51e635c2879a8f2f1a097d2400e57fcee5508c7ac9d113c917e86ac17db7e16aab0604bab4bce1be2013346623ec0bd371392a22cf1b17a661a967beb51937ae2f120525efc55e115e7f26c9af8941494e1c01ed88af4651bb9e367f97a5aa620e076742b28096873f97f4535f6be31350fbe9a58672788503286dc8d51d3f406f15278415ec69f99f396d6220f3f691c95a8707b0cbc9b12c75c551d4b4e7512cf4370584de5864aaf01075a030ffb9da19fb37e2e9'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "eNeez-IyjD9t"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <b> <span style='color:#2ae4f5'>|</span> Rice Variety Classification and Quality Evaluation Using Image Analysis </b>"
      ],
      "metadata": {
        "id": "Wmd6BJeyjD9w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## <b>2 <span style='color:#2ae4f5'>|</span> Import Libraries </b>"
      ],
      "metadata": {
        "id": "pZkZ33D_jD9y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <b>1 <span style='color:#2ae4f5'>|</span> Introduction </b>\n",
        "<div style=\"color:white;display:fill;border-radius:8px;\n",
        "            background-color:#03112A;font-size:150%;\n",
        "            letter-spacing:1.0px;background-image: url(https://i.imgur.com/GVd0La1.png)\">\n",
        "    <p style=\"padding: 8px;color:white;\"><b><b><span style='color:#2ae4f5''>1.1 |</span></b> Rice Variety Classification and Quality Evaluation Using Image Analysis </b></p>\n",
        "</div>\n",
        "        \n",
        "Rice, as one of the most prevalent grain crops globally, exhibits significant genetic diversity, resulting in various rice varieties. These varieties exhibit variations in essential characteristics such as **texture**, **shape**, and **color**. By harnessing these differentiating features, it becomes possible to accurately classify and assess the quality of rice seeds.\n",
        "\n",
        "This research initiative aims to **develop a robust image analysis system** capable of automatically identifying and categorizing different rice varieties based on their visual attributes. By employing advanced **machine learning techniques** and **deep neural networks**, the project endeavors to create a model that can accurately classify rice samples into the five target varieties.\n",
        "\n",
        "Additionally, the developed **image analysis model** can contribute to the broader field of **computer vision** and **pattern recognition**. The insights gained from this research can be applied to other **grain crops** and **agricultural products**, leading to advancements in **automated classification** and quality evaluation across various agricultural domains.\n",
        "\n",
        "In summary, the **Rice Variety Classification and Quality Evaluation project** utilizes a comprehensive dataset of 75,000 rice images to develop a state-of-the-art image analysis system. By accurately classifying and evaluating the quality attributes of five distinct rice varieties, this research aims to enhance rice production processes, support seed selection, and drive advancements in computer vision for agricultural applications. For more information about the dataset use the following Kaggle link:\n",
        "https://www.kaggle.com/datasets/muratkokludataset/rice-image-dataset"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-08-14T19:17:39.966306Z",
          "iopub.execute_input": "2023-08-14T19:17:39.967019Z"
        },
        "id": "dT8kFo1qjD9y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import requirement libraries and tools\n",
        "import os\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set(style= \"darkgrid\", color_codes = True)\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "_kg_hide-output": true,
        "execution": {
          "iopub.status.busy": "2024-05-14T13:32:52.795407Z",
          "iopub.execute_input": "2024-05-14T13:32:52.795839Z",
          "iopub.status.idle": "2024-05-14T13:33:02.717041Z",
          "shell.execute_reply.started": "2024-05-14T13:32:52.795793Z",
          "shell.execute_reply": "2024-05-14T13:33:02.716164Z"
        },
        "trusted": true,
        "id": "XxRgG0fEjD9z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <b>3 <span style='color:#2ae4f5'>|</span> Create a dataframe with the Images and Label </b>"
      ],
      "metadata": {
        "id": "9MmNCWr8jD90"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path = '/kaggle/input/rice-image-dataset/Rice_Image_Dataset'"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-14T13:33:02.718833Z",
          "iopub.execute_input": "2024-05-14T13:33:02.7194Z",
          "iopub.status.idle": "2024-05-14T13:33:02.725693Z",
          "shell.execute_reply.started": "2024-05-14T13:33:02.71937Z",
          "shell.execute_reply": "2024-05-14T13:33:02.724686Z"
        },
        "trusted": true,
        "id": "5PIPD3I4jD90"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save Data to an empty folder\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "images = []\n",
        "labels = []\n",
        "\n",
        "for subfolder in os.listdir(dataset_path):\n",
        "    subfolder_path = os.path.join(dataset_path, subfolder)\n",
        "    if not os.path.isdir(subfolder_path):\n",
        "        continue\n",
        "\n",
        "    # 각 이미지 파일을 읽어서 images와 labels 리스트에 추가\n",
        "    for image_filename in os.listdir(subfolder_path):\n",
        "        image_path = os.path.join(subfolder_path, image_filename)\n",
        "        images.append(image_path)\n",
        "            # 해당 이미지의 레이블을 폴더 이름으로 설정하여 리스트에 추가\n",
        "        labels.append(subfolder)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-14T13:33:02.726927Z",
          "iopub.execute_input": "2024-05-14T13:33:02.727219Z",
          "iopub.status.idle": "2024-05-14T13:33:04.495455Z",
          "shell.execute_reply.started": "2024-05-14T13:33:02.727193Z",
          "shell.execute_reply": "2024-05-14T13:33:04.494657Z"
        },
        "trusted": true,
        "id": "SL1r83bvjD91"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame({'image': images, 'label':labels})\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-14T13:33:04.49742Z",
          "iopub.execute_input": "2024-05-14T13:33:04.497718Z",
          "iopub.status.idle": "2024-05-14T13:33:04.516434Z",
          "shell.execute_reply.started": "2024-05-14T13:33:04.497692Z",
          "shell.execute_reply": "2024-05-14T13:33:04.515466Z"
        },
        "trusted": true,
        "id": "XOc8dF_2jD92"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Take a look at DataFrame\n",
        "\n",
        "# from ydata_profiling import ProfileReport\n",
        "\n",
        "# df_profile = ProfileReport(df)\n",
        "# df_profile.to_notebook_iframe()\n",
        "\n",
        "\n",
        "df.head()\n",
        "df.describe()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-14T13:33:04.517481Z",
          "iopub.execute_input": "2024-05-14T13:33:04.517778Z",
          "iopub.status.idle": "2024-05-14T13:33:04.611129Z",
          "shell.execute_reply.started": "2024-05-14T13:33:04.517753Z",
          "shell.execute_reply": "2024-05-14T13:33:04.610118Z"
        },
        "trusted": true,
        "id": "gvIMNRrsjD93"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <b>4 <span style='color:#2ae4f5'>|</span> Visualization of Dataset </b>"
      ],
      "metadata": {
        "id": "O2shmmhUjD93"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_shape = df['image'].shape\n",
        "image_shape"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-14T13:34:47.471684Z",
          "iopub.execute_input": "2024-05-14T13:34:47.472522Z",
          "iopub.status.idle": "2024-05-14T13:34:47.478295Z",
          "shell.execute_reply.started": "2024-05-14T13:34:47.472491Z",
          "shell.execute_reply": "2024-05-14T13:34:47.47735Z"
        },
        "trusted": true,
        "id": "1mu61h5kjD93"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib.gridspec import GridSpec\n",
        "# Create figure and grid of subplots\n",
        "fig = plt.figure(figsize=(15, 15))\n",
        "gs = GridSpec(5, 4, figure=fig)\n",
        "\n",
        "# Loop through each unique category in the DataFrame\n",
        "for i, category in enumerate(df['label'].unique()):\n",
        "    # Get the filepaths for the first four images in the category\n",
        "    filepaths = df[df['label'] == category]['image'].values[:4]\n",
        "\n",
        "    # Loop through the filepaths and add an image to each subplot\n",
        "    for j, filepath in enumerate(filepaths):\n",
        "        ax = fig.add_subplot(gs[i, j])\n",
        "        ax.imshow(plt.imread(filepath))\n",
        "        ax.axis('off')\n",
        "\n",
        "    # Add a label to the bottom of the subplot grid\n",
        "    ax.text(300, 100, category, fontsize=25, color='darkblue')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-14T13:41:38.017936Z",
          "iopub.execute_input": "2024-05-14T13:41:38.01883Z",
          "iopub.status.idle": "2024-05-14T13:41:40.581575Z",
          "shell.execute_reply.started": "2024-05-14T13:41:38.018788Z",
          "shell.execute_reply": "2024-05-14T13:41:40.580531Z"
        },
        "trusted": true,
        "id": "wEcECc3fjD93"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# COUNTPLOT\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "ax = sns.countplot(data=df, x=df.label)\n",
        "ax.set_xlabel(\"Name of Class\")\n",
        "ax.set_ylabel(\"The Number of Samples for each class\")\n",
        "plt.xticks(rotation=-45)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-14T13:41:43.186381Z",
          "iopub.execute_input": "2024-05-14T13:41:43.187114Z",
          "iopub.status.idle": "2024-05-14T13:41:43.622146Z",
          "shell.execute_reply.started": "2024-05-14T13:41:43.187078Z",
          "shell.execute_reply": "2024-05-14T13:41:43.621209Z"
        },
        "trusted": true,
        "id": "m68jDmWxjD94"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <b>5 <span style='color:#2ae4f5'>|</span> Split Data into Train and Test </b>\n",
        "**I divided our data into two separate datasets:** the **training dataset** and the **testing dataset**. The training dataset consists of **80%** of the data, while the testing dataset contains the remaining **20%**.\n",
        "To facilitate the training process, I applied the **LabelEncoder to labels**. This process allowed us to convert the rice types' labels, namely **'Arborio'**, **'Basmati'**, **'Ipsala'**, **'Jasmine'**, and **'Karacadag'**, into numerical values. By assigning integer values to the labels, we enabled the utilization of these labels as target variables during the training of our machine learning model."
      ],
      "metadata": {
        "id": "Bx8C_C73jD94"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(df.image, df.label, test_size=0.2, random_state=44)\n",
        "\n",
        "df_train = pd.DataFrame({'image' : X_train, 'label' : y_train})\n",
        "df_test = pd.DataFrame({'image' : X_test, 'label' : y_test})"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-14T13:41:44.727324Z",
          "iopub.execute_input": "2024-05-14T13:41:44.728176Z",
          "iopub.status.idle": "2024-05-14T13:41:44.748286Z",
          "shell.execute_reply.started": "2024-05-14T13:41:44.728143Z",
          "shell.execute_reply": "2024-05-14T13:41:44.747508Z"
        },
        "trusted": true,
        "id": "Eo7_pMTbjD94"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#encoding\n",
        "\n",
        "encoder = LabelEncoder()\n",
        "y_train = encoder.fit_transform(y_train)\n",
        "y_test = encoder.fit(y_test)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-14T13:41:45.960194Z",
          "iopub.execute_input": "2024-05-14T13:41:45.961108Z",
          "iopub.status.idle": "2024-05-14T13:41:45.98319Z",
          "shell.execute_reply.started": "2024-05-14T13:41:45.961074Z",
          "shell.execute_reply": "2024-05-14T13:41:45.982173Z"
        },
        "trusted": true,
        "id": "xST-uC8NjD94"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <b>6 <span style='color:#2ae4f5'>|</span> Data Augmentation </b>\n",
        "To streamline the preprocessing of our images, we took the following steps:\n",
        "- **we created generators for both the training and testing datasets.** These generators allow us to efficiently handle and manipulate the data during the training and testing phases.\n",
        "\n",
        "- **to enhance the diversity and robustness of our training data, we applied data augmentation techniques specifically to the training dataset.** This augmentation process introduces variations in the images by applying transformations such as rotation, scaling, and flipping. By doing so, we expand the dataset and enable our model to learn from a wider range of image variations.\n",
        "\n",
        "- **Additionally, we standardized the image dimensions by reshaping them to a uniform size of 50x50 pixels.** This resizing ensures that all images in the dataset have consistent dimensions, facilitating the subsequent processing and analysis stages.\n"
      ],
      "metadata": {
        "id": "phjhU-MnjD94"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "image_size=(60,60)\n",
        "batch_size = 32\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale = 1./255,\n",
        "    rotation_range=45,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range = 0.2,\n",
        "    zoom_range = 0.2,\n",
        "    fill_mode='nearest')\n",
        "\n",
        "\n",
        "train_generator = datagen.flow_from_dataframe(df_train, x_col='image', y_col='label', target_size=image_size,\n",
        "                                             batch_size=batch_size, class_mode='categorical', shuffle='True')\n",
        "\n",
        "test_generator = datagen.flow_from_dataframe(df_test, x_col='image', y_col='label', target_size=image_size,\n",
        "                                             batch_size=batch_size, class_mode='categorical', shuffle='False')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-14T13:41:49.993747Z",
          "iopub.execute_input": "2024-05-14T13:41:49.994108Z",
          "iopub.status.idle": "2024-05-14T13:45:59.514545Z",
          "shell.execute_reply.started": "2024-05-14T13:41:49.994077Z",
          "shell.execute_reply": "2024-05-14T13:45:59.513767Z"
        },
        "trusted": true,
        "id": "o88hkdByjD94"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <b>6 <span style='color:#2ae4f5'>|</span> Training Model </b>"
      ],
      "metadata": {
        "id": "wTfMGhS4jD94"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "input_shape = (60,60,3)\n",
        "\n",
        "model = keras.Sequential([layers.Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=input_shape),\n",
        "                          layers.MaxPool2D(),\n",
        "                          layers.Conv2D(64, kernel_size=(3,3), activation='relu'),layers.MaxPool2D(),\n",
        "                          layers.Conv2D(128, kernel_size=(3,3), activation='relu'),layers.MaxPool2D(),\n",
        "                          layers.Flatten(),\n",
        "                          layers.Dense(32,activation='relu'),\n",
        "                          layers.Dense(5, activation='softmax')])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-14T13:49:10.718761Z",
          "iopub.execute_input": "2024-05-14T13:49:10.719169Z",
          "iopub.status.idle": "2024-05-14T13:49:14.458305Z",
          "shell.execute_reply.started": "2024-05-14T13:49:10.719134Z",
          "shell.execute_reply": "2024-05-14T13:49:14.457512Z"
        },
        "trusted": true,
        "id": "BImkpzk6jD95"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  **7.Compling & Training"
      ],
      "metadata": {
        "id": "eJSa6ltNjD95"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit_generator(train_generator, epochs=3, validation_data=test_generator)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-14T13:54:33.218281Z",
          "iopub.execute_input": "2024-05-14T13:54:33.218672Z",
          "iopub.status.idle": "2024-05-14T14:12:17.892977Z",
          "shell.execute_reply.started": "2024-05-14T13:54:33.218639Z",
          "shell.execute_reply": "2024-05-14T14:12:17.892161Z"
        },
        "trusted": true,
        "id": "AnC8V2iXjD95"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <b>8 <span style='color:#2ae4f5'>|</span> Evaluate The Model </b>"
      ],
      "metadata": {
        "id": "GcLplh4WjD95"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#plot\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.legend(['Train', 'Test'], loc='best')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.legend(['Train', 'Test'], loc='best')\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-14T14:28:08.706252Z",
          "iopub.execute_input": "2024-05-14T14:28:08.707081Z",
          "iopub.status.idle": "2024-05-14T14:28:09.431157Z",
          "shell.execute_reply.started": "2024-05-14T14:28:08.707047Z",
          "shell.execute_reply": "2024-05-14T14:28:09.430232Z"
        },
        "trusted": true,
        "id": "n3CHRtPdjD95"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics = model.evaluate(test_generator)\n",
        "print('Accuracy:', metrics[0])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-14T14:31:41.562857Z",
          "iopub.execute_input": "2024-05-14T14:31:41.563208Z",
          "iopub.status.idle": "2024-05-14T14:32:16.966826Z",
          "shell.execute_reply.started": "2024-05-14T14:31:41.56318Z",
          "shell.execute_reply": "2024-05-14T14:32:16.965905Z"
        },
        "trusted": true,
        "id": "ylMYablBjD95"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Accuracy:', metrics[1])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-14T14:32:28.94615Z",
          "iopub.execute_input": "2024-05-14T14:32:28.946495Z",
          "iopub.status.idle": "2024-05-14T14:32:28.951528Z",
          "shell.execute_reply.started": "2024-05-14T14:32:28.946468Z",
          "shell.execute_reply": "2024-05-14T14:32:28.950561Z"
        },
        "trusted": true,
        "id": "11S-VdggjD95"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <b>9 <span style='color:#2ae4f5'>|</span> Save The Model </b>"
      ],
      "metadata": {
        "id": "sX5yY5LQjD95"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model 추후 모델을 재사용하는 법 알아보기\n",
        "model.save('CNN_model.h5')\n",
        "print (\"Model saved successfully!\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-14T14:35:35.703865Z",
          "iopub.execute_input": "2024-05-14T14:35:35.704673Z",
          "iopub.status.idle": "2024-05-14T14:35:35.742282Z",
          "shell.execute_reply.started": "2024-05-14T14:35:35.704641Z",
          "shell.execute_reply": "2024-05-14T14:35:35.741345Z"
        },
        "trusted": true,
        "id": "587AIriyjD95"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#모델 재사용\n",
        "https://chat.openai.com/share/9f4f2c32-8d5e-4788-bb53-ff94ff648cfc"
      ],
      "metadata": {
        "id": "joJK5fr7jD96"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "FT_KaLl4jD96"
      }
    }
  ]
}